{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing the data files\n",
    "\n",
    "Here we convert the triplets data into dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_file = 'D:\\\\Study\\\\MDM\\\\Project\\\\Reference\\\\Collaborative-Filtering-Million-Song-Dataset\\\\xaa.txt'\n",
    "header_list = [\"listenerID\", \"songID\", \"count\"]\n",
    "df = pd.read_csv(main_file, sep='\\t', names=header_list)\n",
    "df_2 = pd.read_csv('D:\\\\Study\\\\MDM\\\\Project\\\\Reference\\\\Collaborative-Filtering-Million-Song-Dataset\\\\test_triplets_first_half.txt', sep='\\t', names=header_list)\n",
    "df = pd.concat([df, df_2], ignore_index= True)\n",
    "# Grouping and getting sets of songs for each user along with total number of plays\n",
    "df_group_listeners_count = df.groupby('listenerID')['songID'].agg(size=len, set=lambda x: set(x))\n",
    "# Grouping and getting lists of songs for each user along with total number of plays\n",
    "df_group_listeners = df.groupby('listenerID')[['songID', 'count']].apply(lambda g: g.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will be used to create dictionaries from list\n",
    "def get_dict_from_list(temp):\n",
    "    songs_dict = {}\n",
    "    count = 0\n",
    "    for item in temp:\n",
    "        count += item[1]\n",
    "    for item in temp:\n",
    "        songs_dict[item[0]] = item[1] / count\n",
    "    return songs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listenersSongs is a dictionary of user_id as keys and dictionaries with song_ID keys and percentage played as values\n",
    "listenersSongs = df_group_listeners.apply(lambda row: get_dict_from_list(row)).to_dict()\n",
    "# This will have total songs played by each user\n",
    "listenersTotalPlays = df_group_listeners_count.to_dict()['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will have listener IDs to be tested\n",
    "test_listeners = set(\n",
    "    pd.read_csv('D:\\\\Study\\\\MDM\\\\Project\\\\Reference\\\\Collaborative-Filtering-Million-Song-Dataset\\\\test_triplets_first_half.txt', sep='\\t', names=header_list)\n",
    "    ['listenerID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at a random sample from the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4a1da9245202e5769d9504ebd3cb7d5f2faa9d51',\n",
      " {'SOADJQJ12A8C141D38': 0.04113924050632911,\n",
      "  'SOAERUU12A8C13F302': 0.00949367088607595,\n",
      "  'SOAWMBL12AF72A8EE3': 0.0031645569620253164,\n",
      "  'SOAXGDH12A8C13F8A1': 0.0031645569620253164,\n",
      "  'SOBAHRH12A8C1367B1': 0.0031645569620253164,\n",
      "  'SOCJHPS12A6D4F8523': 0.00949367088607595,\n",
      "  'SOCKSGZ12A58A7CA4B': 0.00949367088607595,\n",
      "  'SOCWAVM12A8C1320D5': 0.00949367088607595,\n",
      "  'SOCYYYE12A67020E65': 0.0031645569620253164,\n",
      "  'SODJWHY12A8C142CCE': 0.0031645569620253164,\n",
      "  'SOEKSGJ12A67AE227E': 0.00949367088607595,\n",
      "  'SOELHGL12AB017DB4B': 0.022151898734177215,\n",
      "  'SOELHVX12AB017DB78': 0.00949367088607595,\n",
      "  'SOEPGZU12A6D4F91E1': 0.0031645569620253164,\n",
      "  'SOEYWYP12A6D4F5E9D': 0.0031645569620253164,\n",
      "  'SOFKABN12A8AE476C6': 0.0031645569620253164,\n",
      "  'SOFRQTD12A81C233C0': 0.0379746835443038,\n",
      "  'SOFTVGI12AB017DB6D': 0.00949367088607595,\n",
      "  'SOGAROW12A6D4FBB03': 0.0031645569620253164,\n",
      "  'SOGQJKF12A8C13729E': 0.0031645569620253164,\n",
      "  'SOGTOGA12A6D4F953D': 0.012658227848101266,\n",
      "  'SOHAIXS12A8C1432FF': 0.04430379746835443,\n",
      "  'SOHWXEU12A8C1320D1': 0.060126582278481014,\n",
      "  'SOHYKBC12A58A7CDD2': 0.0031645569620253164,\n",
      "  'SOHYLHP12AB017DB50': 0.02531645569620253,\n",
      "  'SOIEKXV12AC3DF80E5': 0.006329113924050633,\n",
      "  'SOIGGSA12AB0182EAE': 0.006329113924050633,\n",
      "  'SOISKTG12A8C140C25': 0.0031645569620253164,\n",
      "  'SOITCZM12A6D4F9538': 0.012658227848101266,\n",
      "  'SOJKQSF12A6D4F5EE9': 0.00949367088607595,\n",
      "  'SOJYVPY12A8C1442FA': 0.00949367088607595,\n",
      "  'SOKIOQB12A6D4F7101': 0.006329113924050633,\n",
      "  'SOKXBCZ12A8C1367AF': 0.0031645569620253164,\n",
      "  'SOLFXKT12AB017E3E0': 0.0031645569620253164,\n",
      "  'SOLWHSJ12A67AE227B': 0.006329113924050633,\n",
      "  'SOMGXRE12A6D4F9536': 0.012658227848101266,\n",
      "  'SOMVIRK12AB017DB7E': 0.00949367088607595,\n",
      "  'SONTQUO12A6D4F7D8B': 0.015822784810126583,\n",
      "  'SONUVNA12A6D4F86C5': 0.00949367088607595,\n",
      "  'SONYKOW12AB01849C9': 0.11392405063291139,\n",
      "  'SOOPJAT12A6D4F9537': 0.012658227848101266,\n",
      "  'SOOYDMX12A58A7A1EE': 0.012658227848101266,\n",
      "  'SOPNLBX12A8C1377D4': 0.0031645569620253164,\n",
      "  'SOPSYOY12A8C142E0B': 0.00949367088607595,\n",
      "  'SOPVQLJ12A67AE2281': 0.00949367088607595,\n",
      "  'SOQWYAQ12A6D4FB9A3': 0.04746835443037975,\n",
      "  'SOSPBXK12AB017DB72': 0.00949367088607595,\n",
      "  'SOSWREK12AB017DB66': 0.00949367088607595,\n",
      "  'SOTPMXE12A6D4F953C': 0.0189873417721519,\n",
      "  'SOTQKDV12A58A7B823': 0.0031645569620253164,\n",
      "  'SOTTPZH12AB017A918': 0.0031645569620253164,\n",
      "  'SOTTQWU12A6D4FC854': 0.006329113924050633,\n",
      "  'SOTWNDJ12A8C143984': 0.05063291139240506,\n",
      "  'SOUKXIN12A8C133C7F': 0.0031645569620253164,\n",
      "  'SOUVTSM12AC468F6A7': 0.0031645569620253164,\n",
      "  'SOVRXWW12A6D4F74D3': 0.012658227848101266,\n",
      "  'SOWBTPS12A6D4FA5BE': 0.1550632911392405,\n",
      "  'SOWCKVR12A8C142411': 0.0031645569620253164,\n",
      "  'SOWEUOO12A6D4F6D0C': 0.00949367088607595,\n",
      "  'SOXABXH12A6D4FA3F8': 0.00949367088607595,\n",
      "  'SOXLJXH12A8C13D903': 0.006329113924050633,\n",
      "  'SOXXACF12A6D4F953E': 0.012658227848101266,\n",
      "  'SOYCWZQ12A6701F1FC': 0.012658227848101266,\n",
      "  'SOZBZSY12A6D4FA404': 0.0031645569620253164}]\n",
      "['cede9ff995828683937f1200d480986b975f692c', 122]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['011ed4402dae54389b9f1f24001b975eaa87d494',\n",
       " '00aab92d3ff5ccc7da850520824ce01039f2ef17',\n",
       " '004a8a7e06ed67e6bbf11377cefbad127f5891c6',\n",
       " '0061902fe653fd807da2edf99cc7a2c5c55cc74c',\n",
       " '0054bb08f34f416c9688600b5318efc1fb4158ed',\n",
       " '00e36dbf522aecb9a10556a248524175dbd02475',\n",
       " '0126bc66b79a8c0c499cab9ff3f96ac7b63d7395',\n",
       " '011abe23d43bedd355041dddd994b86ebdb83675',\n",
       " '00a92fddbc755f66b6650720b29960c4f4161e81',\n",
       " '00e62a101d89b3c782898e536f17869715a9ca3e']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand1 = random.choice(list(listenersSongs.keys()))\n",
    "pprint([rand1, listenersSongs[rand1]])\n",
    "rand2 = random.choice(list(listenersTotalPlays.keys()))\n",
    "pprint([rand2, listenersTotalPlays[random.choice(list(listenersTotalPlays.keys()))]])\n",
    "random.sample(test_listeners, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to generate similarity and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to calculate score from two song percentages\n",
    "def calc_common_percent(perc1, perc2):\n",
    "    smaller = min(perc1, perc2)\n",
    "    larger = max(perc1, perc2)\n",
    "    return smaller + ((smaller / larger) * (larger - smaller))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For two users, for all the common songs, this function will be used to generate two scores\n",
    "# One is percentage of common songs and other is percentage of count of songs played in common\n",
    "def generate_similarity_measure(first_dict, second_dict, user_1_total_plays, user_2_total_plays, common_songs):\n",
    "    perc_common = 0.0\n",
    "    perc_count_common = 0.0\n",
    "\n",
    "    for song in common_songs:\n",
    "        user_1_play_count = first_dict[song]\n",
    "        user_2_play_count = second_dict[song]\n",
    "\n",
    "        perc_common += calc_common_percent(user_1_play_count, user_2_play_count)\n",
    "\n",
    "        p1 = user_1_play_count * user_1_total_plays\n",
    "        p2 = user_2_play_count * user_2_total_plays\n",
    "        perc_count_common += calc_common_percent(p1, p2)\n",
    "\n",
    "    return [perc_common, perc_count_common]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the main function used to generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes pre processed data and user_ids to be tested as input\n",
    "def recommend_by_similarity(test_user_ids, user_total_plays_map, user_song_percentage_map, limiting_factor, power=1):\n",
    "    recommendation_set = {}\n",
    "    count = 0\n",
    "    tot_test_ids = len(test_user_ids)\n",
    "\n",
    "    for user_1 in test_user_ids:\n",
    "        similarity_score_map = {}\n",
    "\n",
    "        count += 1\n",
    "        if count % 30 == 1 :\n",
    "            print(\"Test listener \", count, \" of \", tot_test_ids)\n",
    "\n",
    "        for user_2, user_2_songs_perc_map in user_song_percentage_map.items():\n",
    "\n",
    "            if user_1 != user_2:\n",
    "#                 Get common songs between current user and every other user\n",
    "                common_songs = {k for k in user_song_percentage_map[user_1].keys() if k in user_2_songs_perc_map}\n",
    "#                  If there are any common songs, using the song measure and other stats, generate a score for this user\n",
    "                if len(common_songs) != 0:\n",
    "                    similarity_score_map[user_2] = generate_similarity_measure(user_song_percentage_map[user_1],\n",
    "                                                                               user_2_songs_perc_map,\n",
    "                                                                               user_total_plays_map[user_1],\n",
    "                                                                               user_total_plays_map[user_2],\n",
    "                                                                               common_songs)\n",
    "\n",
    "        rescaling_factors = []\n",
    "        for i in range(2):\n",
    "            max_val = max([v[i] for v in similarity_score_map.values()])\n",
    "            factor = 1.0 / max_val if max_val != 0 else 0.0\n",
    "            rescaling_factors.append(factor)\n",
    "            \n",
    "#         Summing all the percentages for all similar songs, get a single score for all users\n",
    "\n",
    "        similarity_score_map = {k: sum(np.array(v) * np.array(rescaling_factors)) ** power for k, v in\n",
    "                                similarity_score_map.items()}\n",
    "        numRecsRequired = len(user_song_percentage_map[user_1])\n",
    "\n",
    "        maximum_similarity_score = max(similarity_score_map.values())\n",
    "\n",
    "        recommendations = {}\n",
    "\n",
    "        if count % 30 == 1 :\n",
    "            print(\"Recommending for listener, \", count)\n",
    "\n",
    "#         Sorting by highest scored user first, make recommendations\n",
    "        for user_2, similarity in sorted(similarity_score_map.items(), key=lambda x: x[1], reverse=True):\n",
    "            if len(recommendations) >= numRecsRequired and similarity < limiting_factor * maximum_similarity_score:\n",
    "                break\n",
    "#             Get songs which curr user have not listened but the other one has. Add those to recommendations\n",
    "            user1_not_listened_songs = {key: val for key, val in user_song_percentage_map[user_2].items() if\n",
    "                                        key not in user_song_percentage_map[user_1]}\n",
    "            for song_id, perc_played in user1_not_listened_songs.items():\n",
    "                if song_id not in recommendations:\n",
    "                    recommendations[song_id] = perc_played * similarity\n",
    "                else:\n",
    "                    recommendations[song_id] += perc_played * similarity\n",
    "        recommendation_set[user_1] = [k for k in sorted(recommendations, key=recommendations.get, reverse=True)]\n",
    "    print('Finished recommending')\n",
    "    return recommendation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find matched songs and get score. 0 if none\n",
    "def check_hit_count_score(actual_listened_songs, predicted_songs, threshold=10):\n",
    "    if len(predicted_songs) > threshold:\n",
    "        predicted_songs = predicted_songs[:threshold]\n",
    "    hit_score = 0.0\n",
    "    number_of_matched_songs = 0.0    \n",
    "    for index, song in enumerate(predicted_songs):\n",
    "        if song in actual_listened_songs and song not in predicted_songs[:index]:\n",
    "            number_of_matched_songs += 1.0\n",
    "            hit_score += number_of_matched_songs / (index + 1.0)\n",
    "    if not actual_listened_songs:\n",
    "        return 0.0\n",
    "    return hit_score / min(len(actual_listened_songs), threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average score\n",
    "def get_average_recommendation_score(actual_list, predicted_list, threshold=10):\n",
    "    return np.mean([check_hit_count_score(actual_song, predicted_song, threshold) for actual_song, predicted_song in\n",
    "                    zip(actual_list, predicted_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionaries to lists to conveniently genearte scores\n",
    "def calculate_whole_mean_score(recommended_songs_map, actual_songs_map):\n",
    "    recommended_songs_list = []\n",
    "    actual_songs_list = []\n",
    "    for user_id, actual_songs in actual_songs_map.items():\n",
    "        actual_songs_list.append(actual_songs)\n",
    "        recommended_songs_list.append(recommended_songs_map[user_id])\n",
    "    return get_average_recommendation_score(actual_songs_list, recommended_songs_list, 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing analysis and on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set is taken separately and split into two halves. One half of the data will be used to make predictions and the other half will be used to verify if the recommendations match the actual listened songs or not.\n",
    "\n",
    "One file is test_triplets_first_half.txt and other is test_triplets_second_half.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will have all the user_ids to be tested. \n",
    "#Songs these users listened(first half) will already be there in the training dictionaries\n",
    "test_listeners = set(\n",
    "    pd.read_csv('D:\\\\Study\\\\MDM\\\\Project\\\\Reference\\\\Collaborative-Filtering-Million-Song-Dataset\\\\test_triplets_first_half.txt', sep='\\t', names=header_list)['listenerID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test listener  1  of  526\n",
      "Recommending for listener,  1\n",
      "Test listener  31  of  526\n",
      "Recommending for listener,  31\n",
      "Test listener  61  of  526\n",
      "Recommending for listener,  61\n",
      "Test listener  91  of  526\n",
      "Recommending for listener,  91\n",
      "Test listener  121  of  526\n",
      "Recommending for listener,  121\n",
      "Test listener  151  of  526\n",
      "Recommending for listener,  151\n",
      "Test listener  181  of  526\n",
      "Recommending for listener,  181\n",
      "Test listener  211  of  526\n",
      "Recommending for listener,  211\n",
      "Test listener  241  of  526\n",
      "Recommending for listener,  241\n",
      "Test listener  271  of  526\n",
      "Recommending for listener,  271\n",
      "Test listener  301  of  526\n",
      "Recommending for listener,  301\n",
      "Test listener  331  of  526\n",
      "Recommending for listener,  331\n",
      "Test listener  361  of  526\n",
      "Recommending for listener,  361\n",
      "Test listener  391  of  526\n",
      "Recommending for listener,  391\n",
      "Test listener  421  of  526\n",
      "Recommending for listener,  421\n",
      "Test listener  451  of  526\n",
      "Recommending for listener,  451\n",
      "Test listener  481  of  526\n",
      "Recommending for listener,  481\n",
      "Test listener  511  of  526\n",
      "Recommending for listener,  511\n",
      "Finished recommending\n"
     ]
    }
   ],
   "source": [
    "# Calling the main method to generate recommendations\n",
    "listenersRecs = recommend_by_similarity(test_listeners, listenersTotalPlays, listenersSongs, .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate the actual songs the user has listened to. The second half of the test set\n",
    "header_list = [\"listenerID\", \"songID\", \"count\"]\n",
    "df_answers = pd.read_csv('test_triplets_second_half.txt', sep='\\t', names=header_list)\n",
    "actual_listened_songs_map = df_answers.groupby('listenerID')['songID'].agg(lambda x: set(x)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10311862633478829\n"
     ]
    }
   ],
   "source": [
    "# Use the formulae to calculate recommendation score\n",
    "print(calculate_whole_mean_score(listenersRecs, actual_listened_songs_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(open(\"listenersRecs.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score is around 10-12 for this dataset. This is almost 5 times better than recommending randomly or recommending popular songs. Still, as this is a basic type of recommendation system, accuracy can be considered low. ALS methods, which will be done sepaately will have better accuracy than this method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Song names from recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listenersRecs = pickle.load(open(\"listenersRecs.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01146c36fd0738038720f8362cbe71e79999ca25'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand2 = random.choice(list(listenersRecs.keys()))\n",
    "rand2\n",
    "# rand2 = '00ab1b0140bbc682342526b017be0f14cca42653'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.read_csv('test_triplets_second_half.txt', sep='\\t', names=header_list)\n",
    "answers = df_answers.loc[df_answers['listenerID'] == rand2]['songID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_songs = listenersRecs[rand2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('D:\\\\Study\\\\MDM\\\\Project\\\\DataSet\\\\DataSet\\\\track_metadata.csv', error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual listened songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>316198</th>\n",
       "      <td>Midlife Crisis</td>\n",
       "      <td>Faith No More</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320960</th>\n",
       "      <td>Not Me</td>\n",
       "      <td>Datarock</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440898</th>\n",
       "      <td>Myth Takes</td>\n",
       "      <td>!!!</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534342</th>\n",
       "      <td>Last Cup Of Sorrow</td>\n",
       "      <td>Faith No More</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621186</th>\n",
       "      <td>Bodhisattva</td>\n",
       "      <td>Steely Dan</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716826</th>\n",
       "      <td>Wicked Garden (LP Version)</td>\n",
       "      <td>Stone Temple Pilots</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title          artist_name  year\n",
       "316198              Midlife Crisis        Faith No More  1992\n",
       "320960                      Not Me             Datarock  2007\n",
       "440898                  Myth Takes                  !!!  2007\n",
       "534342          Last Cup Of Sorrow        Faith No More  1997\n",
       "621186                 Bodhisattva           Steely Dan  1973\n",
       "716826  Wicked Garden (LP Version)  Stone Temple Pilots  2003"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.loc[df_meta['song_id'].isin(answers)][['title', 'artist_name', 'year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>The Maestro</td>\n",
       "      <td>Beastie Boys</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195655</th>\n",
       "      <td>Représente</td>\n",
       "      <td>Alliance Ethnik</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299147</th>\n",
       "      <td>Jamaica Roots II(Agora E Sempre)</td>\n",
       "      <td>Natiruts</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550400</th>\n",
       "      <td>Glamour y Violencia</td>\n",
       "      <td>Once Tiros</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669775</th>\n",
       "      <td>Better Man</td>\n",
       "      <td>Pearl Jam</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763712</th>\n",
       "      <td>Eleanor Put Your Boots On</td>\n",
       "      <td>Franz Ferdinand</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804312</th>\n",
       "      <td>Kids In America</td>\n",
       "      <td>Bloodhound Gang</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879955</th>\n",
       "      <td>3 Rounds and a Sound</td>\n",
       "      <td>Blind Pilot</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907597</th>\n",
       "      <td>Eleanor Put Your Boots On</td>\n",
       "      <td>Franz Ferdinand</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933652</th>\n",
       "      <td>Forever</td>\n",
       "      <td>Drake / Kanye West / Lil Wayne / Eminem</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971120</th>\n",
       "      <td>Flume</td>\n",
       "      <td>Bon Iver</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "5998                         The Maestro   \n",
       "195655                        Représente   \n",
       "299147  Jamaica Roots II(Agora E Sempre)   \n",
       "550400               Glamour y Violencia   \n",
       "669775                        Better Man   \n",
       "763712         Eleanor Put Your Boots On   \n",
       "804312                   Kids In America   \n",
       "879955              3 Rounds and a Sound   \n",
       "907597         Eleanor Put Your Boots On   \n",
       "933652                           Forever   \n",
       "971120                             Flume   \n",
       "\n",
       "                                    artist_name  year  \n",
       "5998                               Beastie Boys  1992  \n",
       "195655                          Alliance Ethnik  1999  \n",
       "299147                                 Natiruts     0  \n",
       "550400                               Once Tiros  2005  \n",
       "669775                                Pearl Jam  1994  \n",
       "763712                          Franz Ferdinand  2005  \n",
       "804312                          Bloodhound Gang  1995  \n",
       "879955                              Blind Pilot  2008  \n",
       "907597                          Franz Ferdinand  2005  \n",
       "933652  Drake / Kanye West / Lil Wayne / Eminem     0  \n",
       "971120                                 Bon Iver  2007  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.loc[df_meta['song_id'].isin(suggested_songs)][['title', 'artist_name', 'year']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
