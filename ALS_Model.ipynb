{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.0.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.8.2 (default, Mar 26 2020 15:53:00)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import os\n",
    "\n",
    "from pyspark.shell import sqlContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list directories\n",
    "files_path = '../MDM_Project/Dataset/'  # File path here ../MDM_Project/Dataset/\n",
    "\n",
    "triplets_file = files_path + 'train_triplets.txt'\n",
    "songs2tracks_file = files_path + 'song_to_tracks.txt'\n",
    "metadata_file = files_path + 'track_metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Windows.\n",
    "if os.path.sep != '/':\n",
    "    triplets_file = triplets_file.replace('/', os.path.sep)\n",
    "    songs2tracks_file = songs2tracks_file.replace('/', os.path.sep)\n",
    "    metadata_file = metadata_file.replace('/', os.path.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating schema so the cluster only runs through the data once\n",
    "triplets_schema = StructType(\n",
    "    [StructField('userId', StringType()),\n",
    "     StructField('songId', StringType()),\n",
    "     StructField('Plays', IntegerType())]\n",
    ")\n",
    "songs2tracks_schema = StructType(\n",
    "    [StructField('songId', StringType()),\n",
    "     StructField('trackId', StringType())]\n",
    ")\n",
    "metadata_schema = StructType(\n",
    "    [StructField('trackId', StringType()),\n",
    "     StructField('title', StringType()),\n",
    "     StructField('songId', StringType()),\n",
    "     StructField('release', StringType()),\n",
    "     StructField('artist_id', StringType()),\n",
    "     StructField('artist_mbid', StringType()),\n",
    "     StructField('artist_name', StringType()),\n",
    "     StructField('duration', DoubleType()),\n",
    "     StructField('artist_familiarity', DoubleType()),\n",
    "     StructField('artist_hotttness', DoubleType()),\n",
    "     StructField('year', IntegerType()),\n",
    "     StructField('track_7digitalid', IntegerType()),\n",
    "     StructField('shs_perf', DoubleType()),\n",
    "     StructField('shs_work', DoubleType())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into DataFrames\n",
    "plays_df = sqlContext.read.format('com.databricks.spark.csv') \\\n",
    "    .options(delimiter='\\t', header=True, inferSchema=False) \\\n",
    "    .schema(triplets_schema) \\\n",
    "    .load(triplets_file)\n",
    "\n",
    "songs2tracks_df = sqlContext.read.format('com.databricks.spark.csv') \\\n",
    "    .options(delimiter=',', header=True, inferSchema=False) \\\n",
    "    .schema(songs2tracks_schema) \\\n",
    "    .load(songs2tracks_file)\n",
    "\n",
    "metadata_df = sqlContext.read.format('com.databricks.spark.csv') \\\n",
    "    .options(delimiter=',', header=True, inferSchema=False) \\\n",
    "    .schema(metadata_schema) \\\n",
    "    .load(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ids from strings to integers\n",
    "userId_change = plays_df.select('userId').distinct().select('userId',F.monotonically_increasing_id().alias('new_userId'))\n",
    "user_als_id_LUT = sqlContext.createDataFrame(userId_change.rdd.map(lambda x: x[0]).zipWithIndex(), StructType([StructField(\"userId\", StringType(), True),StructField(\"user_als_id\", IntegerType(), True)]))\n",
    "\n",
    "songId_change = plays_df.select('songId').distinct().select('songId', F.monotonically_increasing_id().alias('new_songId'))\n",
    "song_als_id_LUT = sqlContext.createDataFrame(songId_change.rdd.map(lambda x: x[0]).zipWithIndex(), StructType([StructField(\"songId\", StringType(), True),StructField(\"song_als_id\", IntegerType(), True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|              userId|user_als_id|\n",
      "+--------------------+-----------+\n",
      "|b11e6a84c54160e61...|          0|\n",
      "|2c218a60b3d777e9e...|          1|\n",
      "|672a1973a091e8ed8...|          2|\n",
      "|e51bbbd28659be401...|          3|\n",
      "|cc9fc2eccf0d6fe78...|          4|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------+-----------+\n",
      "|            songId|song_als_id|\n",
      "+------------------+-----------+\n",
      "|SOAQZXK12A6701D993|          0|\n",
      "|SODASIJ12A6D4F5D89|          1|\n",
      "|SOPQGWI12A8C135DDB|          2|\n",
      "|SOHNFBA12AB018CD1D|          3|\n",
      "|SOMMUEG12AF729B982|          4|\n",
      "+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN THE BLOCK TO CHECK IF THE  NEW USER_ID, SONG_ID GENERATED PROPERLY\n",
    "user_als_id_LUT.show(5)\n",
    "song_als_id_LUT.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 88750\n",
      "Number of unique songs: 248144\n"
     ]
    }
   ],
   "source": [
    "# RUN THE BLOCK TO Get total unique users and songs\n",
    "unique_users = user_als_id_LUT.count()\n",
    "unique_songs = song_als_id_LUT.count()\n",
    "print('Number of unique users: {0}'.format(unique_users))\n",
    "print('Number of unique songs: {0}'.format(unique_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the new ID's to the Plays_df\n",
    "plays_df_2 = plays_df.join(user_als_id_LUT,'userId').join(song_als_id_LUT,'songId')\n",
    "\n",
    "# remove half users to make more manageable\n",
    "plays_df_2 = plays_df_2.filter(plays_df_2.user_als_id < unique_users / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "|            songId|              userId|Plays|user_als_id|song_als_id|\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "|SOAADAS12A58A784EC|72b850a0b614bf2ca...|    1|       5675|        483|\n",
      "|SOAAZPG12A6D4F8D8B|06e2112e9fa9a5305...|    2|       1649|        116|\n",
      "|SOAAZPG12A6D4F8D8B|36d2c3cf1eacc5161...|    2|       1608|        116|\n",
      "|SOAAZPG12A6D4F8D8B|27c21f013bf67bc60...|    1|       6329|        116|\n",
      "|SOAAZPG12A6D4F8D8B|8c87aae74e9644017...|    2|       6628|        116|\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------+--------------------+\n",
      "|            songId|             trackId|\n",
      "+------------------+--------------------+\n",
      "|TRMMMYQ128F932D901|  SOQMMHC12AB0180CB8|\n",
      "|TRMMMKD128F425225D|  SOVFVAK12A8C1350D9|\n",
      "|TRMMMRX128F93187D9|  SOGTUKN12AB017F4F1|\n",
      "|TRMMMCH128F425532C|  SOBNYVR12A8C13558C|\n",
      "|TRMMMWA128F426B589|  SOHSBXH12A8C13B0DF|\n",
      "+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------+-----------------+------------------+--------------------+------------------+--------------------+----------------+---------+------------------+----------------+----+----------------+--------+--------+\n",
      "|           trackId|            title|            songId|             release|         artist_id|         artist_mbid|     artist_name| duration|artist_familiarity|artist_hotttness|year|track_7digitalid|shs_perf|shs_work|\n",
      "+------------------+-----------------+------------------+--------------------+------------------+--------------------+----------------+---------+------------------+----------------+----+----------------+--------+--------+\n",
      "|TRMMMYQ128F932D901|     Silent Night|SOQMMHC12AB0180CB8|Monster Ballads X...|ARYZTJS1187B98C555|357ff05d-848a-44c...|Faster Pussy cat|252.05506|    0.649822100201|  0.394031892714|2003|         7032331|    -1.0|     0.0|\n",
      "|TRMMMKD128F425225D|      Tanssi vaan|SOVFVAK12A8C1350D9|         Karkuteillä|ARMVN3U1187FB3A1EB|8d7ef530-a6fd-4f8...|Karkkiautomaatti|156.55138|    0.439603966677|  0.356992107756|1995|         1514808|    -1.0|     0.0|\n",
      "|TRMMMRX128F93187D9|No One Could Ever|SOGTUKN12AB017F4F1|              Butter|ARGEKB01187FB50750|3d403d44-36ce-465...|  Hudson Mohawke|138.97098|    0.643680572058|  0.437503836595|2006|         6945353|    -1.0|     0.0|\n",
      "|TRMMMCH128F425532C|    Si Vos Querés|SOBNYVR12A8C13558C|             De Culo|ARNWYLR1187B9B2F9C|12be7648-7094-495...|     Yerba Brava|145.05751|    0.448501159656|  0.372349068517|2003|         2168257|    -1.0|     0.0|\n",
      "|TRMMMWA128F426B589| Tangle Of Aspens|SOHSBXH12A8C13B0DF|Rene Ablaze Prese...|AREQDTE1269FB37231|                null|      Der Mystic|514.29832|               0.0|             0.0|   0|         2264873|    -1.0|     0.0|\n",
      "+------------------+-----------------+------------------+--------------------+------------------+--------------------+----------------+---------+------------------+----------------+----+----------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary of each DataFrame\n",
    "plays_df_2.cache()\n",
    "plays_df_2.show(5)\n",
    "\n",
    "songs2tracks_df.cache()\n",
    "songs2tracks_df.show(5)\n",
    "\n",
    "metadata_df.cache()\n",
    "metadata_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Listens of Each SONG_ID:\n",
      "+------------------+----------+-----------+\n",
      "|songId            |User_Count|Total_Plays|\n",
      "+------------------+----------+-----------+\n",
      "|SOBONKR12A58A7A7E0|3682      |31851      |\n",
      "|SOAUWYT12A81C206F1|4026      |28582      |\n",
      "|SOSXLTC12AF72A7F54|3585      |23166      |\n",
      "|SOEGIYH12A6D4FC0E3|3087      |18587      |\n",
      "|SOFRQTD12A81C233C0|4827      |18295      |\n",
      "|SOAXGDH12A8C13F8A1|4032      |15470      |\n",
      "+------------------+----------+-----------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Total Listens(plays) of Each SongID\n",
    "Total_listens = plays_df_2.groupBy('songId') \\\n",
    "                                              .agg(F.count(plays_df_2.Plays).alias('User_Count'),\n",
    "                                                            F.sum(plays_df_2.Plays).alias('Total_Plays')) \\\n",
    "                                                       .orderBy('Total_Plays', ascending = False)\n",
    "\n",
    "print('Total Listens of Each SONG_ID:')\n",
    "Total_listens.show(6, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Details of Songs Listened\n",
      "+----------------------------------------------------------------------+-------------------------------------------------------------------+------------------+----------+-----------+\n",
      "|artist_name                                                           |title                                                              |songId            |User_Count|Total_Plays|\n",
      "+----------------------------------------------------------------------+-------------------------------------------------------------------+------------------+----------+-----------+\n",
      "|Dwight Yoakam                                                         |You're The One                                                     |SOBONKR12A58A7A7E0|3682      |31851      |\n",
      "|Björk                                                                 |Undo                                                               |SOAUWYT12A81C206F1|4026      |28582      |\n",
      "|Kings Of Leon                                                         |Revelry                                                            |SOSXLTC12AF72A7F54|3585      |23166      |\n",
      "|Barry Tuckwell/Academy of St Martin-in-the-Fields/Sir Neville Marriner|Horn Concerto No. 4 in E flat K495: II. Romance (Andante cantabile)|SOEGIYH12A6D4FC0E3|3087      |18587      |\n",
      "|Harmonia                                                              |Sehr kosmisch                                                      |SOFRQTD12A81C233C0|4827      |18295      |\n",
      "|Florence + The Machine                                                |Dog Days Are Over (Radio Edit)                                     |SOAXGDH12A8C13F8A1|4032      |15470      |\n",
      "|OneRepublic                                                           |Secrets                                                            |SONYKOW12AB01849C9|3425      |12542      |\n",
      "|Five Iron Frenzy                                                      |Canada                                                             |SOPUCYA12A8C13A694|2060      |12460      |\n",
      "|Tub Ring                                                              |Invalid                                                            |SOUFTBI12AB0183F65|1664      |11222      |\n",
      "|Alliance Ethnik                                                       |Représente                                                         |SOOFYTN12A6D4F9B35|1767      |10704      |\n",
      "+----------------------------------------------------------------------+-------------------------------------------------------------------+------------------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Joining with metadata to get artist and song title for the Total_Listens\n",
    "Song_names = Total_listens.join(metadata_df, 'songId' ) \\\n",
    "                                                      .filter('User_Count >= 200') \\\n",
    "                                                      .select('artist_name', 'title', 'songId', 'User_Count','Total_Plays') \\\n",
    "                                                      .orderBy('Total_Plays', ascending = False)\n",
    "\n",
    "print('Complete Details of Songs Listened')\n",
    "Song_names.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLITING THE DATASET INTO TRAIN, TEST & VALIDATION SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 1265744, validation: 422123, test: 423137\n",
      "\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "|            songId|              userId|Plays|user_als_id|song_als_id|\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "|SOAADAS12A58A784EC|72b850a0b614bf2ca...|    1|       5675|        483|\n",
      "|SOAAZPG12A6D4F8D8B|06e2112e9fa9a5305...|    2|       1649|        116|\n",
      "|SOAAZPG12A6D4F8D8B|1c42d0656661832a3...|    1|      15145|        116|\n",
      "|SOAAZPG12A6D4F8D8B|2720bf07577332aac...|    1|      12927|        116|\n",
      "|SOAAZPG12A6D4F8D8B|27c21f013bf67bc60...|    1|       6329|        116|\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "|            songId|              userId|Plays|user_als_id|song_als_id|\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "|SOAAZPG12A6D4F8D8B|0ba364be007519415...|    1|      39285|        116|\n",
      "|SOAAZPG12A6D4F8D8B|399d1e9bc1ae37682...|    2|      32465|        116|\n",
      "|SOAAZPG12A6D4F8D8B|436122fe92bb4955f...|    1|      17579|        116|\n",
      "|SOAAZPG12A6D4F8D8B|bb84b605789d89899...|    1|      41660|        116|\n",
      "|SOAEBYL12AC468B119|2780f0ed8d98849f8...|    1|      25809|        237|\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "|            songId|              userId|Plays|user_als_id|song_als_id|\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "|SOAAZPG12A6D4F8D8B|3d6196519826c0172...|    1|      30266|        116|\n",
      "|SOAAZPG12A6D4F8D8B|4b49956d0855007f8...|    1|       8936|        116|\n",
      "|SOAAZPG12A6D4F8D8B|4b9b56cb53e598485...|    1|      27173|        116|\n",
      "|SOAAZPG12A6D4F8D8B|7f5e8183039058993...|   17|      35349|        116|\n",
      "|SOADAXB12AB017CCF8|407d4e1223f97e59d...|    2|       9758|        393|\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We'll hold out 60% for training, 20% of our data for validation, and leave 20% for testing\n",
    "seed = 180229192\n",
    "(split_1, split_2, split_3) = plays_df_2.randomSplit([0.6, 0.2, 0.2], seed = seed)\n",
    "\n",
    "# Let's cache these datasets for performance\n",
    "train_set = split_1.cache()\n",
    "validation_set = split_2.cache()\n",
    "test_set = split_3.cache()\n",
    "\n",
    "print('Training: {0}, validation: {1}, test: {2}\\n'.format(\n",
    "  train_set.count(), validation_set.count(), test_set.count())\n",
    ")\n",
    "train_set.show(5)\n",
    "validation_set.show(5)\n",
    "test_set.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "|            songId|              userId|Plays|user_als_id|song_als_id|\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "|SOAAZPG12A6D4F8D8B|0ba364be007519415...|  1.0|      39285|        116|\n",
      "|SOAAZPG12A6D4F8D8B|399d1e9bc1ae37682...|  2.0|      32465|        116|\n",
      "|SOAAZPG12A6D4F8D8B|436122fe92bb4955f...|  1.0|      17579|        116|\n",
      "|SOAAZPG12A6D4F8D8B|bb84b605789d89899...|  1.0|      41660|        116|\n",
      "|SOAEBYL12AC468B119|2780f0ed8d98849f8...|  1.0|      25809|        237|\n",
      "+------------------+--------------------+-----+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of plays needs to be double type\n",
    "validation_set = validation_set.withColumn(\"Plays\", validation_set[\"Plays\"].cast(DoubleType()))\n",
    "validation_set.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL GENERATION (Alternating Least Squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALS_9cc061c3aed0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialising our First ALS learner\n",
    "als_01 = ALS()\n",
    "# Setting the parameters for the method\n",
    "als_01.setMaxIter(5)\\\n",
    "   .setSeed(seed)\\\n",
    "   .setItemCol(\"song_als_id\")\\\n",
    "   .setRatingCol(\"Plays\")\\\n",
    "   .setUserCol(\"user_als_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank : 4  regularization parameter: 0.15  the RMSE is 7.264644516563655\n",
      "For rank : 8  regularization parameter: 0.15  the RMSE is 6.640101260086675\n",
      "For rank : 12  regularization parameter: 0.15  the RMSE is 6.467822764651799\n",
      "For rank : 16  regularization parameter: 0.15  the RMSE is 6.264071090807914\n",
      "For rank : 4  regularization parameter: 0.2  the RMSE is 7.018550737612064\n",
      "For rank : 8  regularization parameter: 0.2  the RMSE is 6.457395112480655\n",
      "For rank : 12  regularization parameter: 0.2  the RMSE is 6.28958308758756\n",
      "For rank : 16  regularization parameter: 0.2  the RMSE is 6.206920879675748\n",
      "For rank : 4  regularization parameter: 0.25  the RMSE is 6.882385757354028\n",
      "For rank : 8  regularization parameter: 0.25  the RMSE is 6.350196847342608\n",
      "For rank : 12  regularization parameter: 0.25  the RMSE is 6.203698598333162\n",
      "For rank : 16  regularization parameter: 0.25  the RMSE is 6.1651038673686305\n",
      "The best model was trained with regularization parameter 0.25\n",
      "The best model was trained with rank 16\n"
     ]
    }
   ],
   "source": [
    "# computing an evaluation metric for our test dataset\n",
    "# We Create an RMSE evaluator using the label and predicted columns\n",
    "\n",
    "reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"Plays\", metricName=\"rmse\")\n",
    "\n",
    "tolerance = 0.03\n",
    "ranks = [4, 8, 12, 16]\n",
    "regParams = [0.15, 0.2, 0.25]\n",
    "errors = [[0]*len(ranks)]*len(regParams)\n",
    "models = [[0]*len(ranks)]*len(regParams)\n",
    "err = 0\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "\n",
    "i = 0\n",
    "for regParam in regParams:\n",
    "  j = 0\n",
    "  for rank in ranks:\n",
    "    # Set the rank here:\n",
    "    als_01.setParams(rank = rank, regParam = regParam)\n",
    "    # Create the model with these parameters.\n",
    "    model = als_01.fit(train_set)\n",
    "    # Run the model to create a prediction. Predict against the validation_df.\n",
    "    predictions = model.transform(validation_set)\n",
    "\n",
    "    # Remove NaN values from prediction (due to SPARK-14489)\n",
    "    predicted_plays = predictions.filter(predictions.prediction != float('nan'))\n",
    "    predicted_plays = predicted_plays.withColumn(\"prediction\", F.abs(F.round(predicted_plays[\"prediction\"],0)))\n",
    "\n",
    "    # Run the previously created RMSE evaluator, reg_eval, on the predicted_plays DataFrame\n",
    "    error = reg_eval.evaluate(predicted_plays)\n",
    "    errors[i][j] = error\n",
    "    models[i][j] = model\n",
    "    print ('For rank :',rank, ' regularization parameter:', regParam,' the RMSE is', error)\n",
    "    if error < min_error:\n",
    "      min_error = error\n",
    "      best_params = [i,j]\n",
    "    j += 1\n",
    "  i += 1\n",
    "\n",
    "als_01.setRegParam(regParams[best_params[0]])\n",
    "als_01.setRank(ranks[best_params[1]])\n",
    "print ('The best model was trained with regularization parameter %s' % regParams[best_params[0]])\n",
    "print ('The best model was trained with rank %s' % ranks[best_params[1]])\n",
    "my_model = models[best_params[0]][best_params[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-----+-----------+-----------+----------+\n",
      "|            songId|              userId|Plays|user_als_id|song_als_id|prediction|\n",
      "+------------------+--------------------+-----+-----------+-----------+----------+\n",
      "|SOYIYOG12A6D4F98CD|82ce98a5021005df7...|  1.0|       2748|        148|       2.0|\n",
      "|SOYIYOG12A6D4F98CD|4f67cb97dee7ef34e...|  1.0|      10049|        148|       5.0|\n",
      "|SOYIYOG12A6D4F98CD|cbe161a3d8767529b...|  6.0|      18605|        148|       1.0|\n",
      "|SOYIYOG12A6D4F98CD|96b86ce393f1b6545...|  5.0|       4877|        148|       2.0|\n",
      "|SOYIYOG12A6D4F98CD|56c0159379617eb13...|  3.0|      33898|        148|       2.0|\n",
      "|SOYIYOG12A6D4F98CD|fe0add7149c2ca4cb...|  4.0|      41079|        148|       2.0|\n",
      "|SOYIYOG12A6D4F98CD|b1d7e37caa99f45b1...|  1.0|      26292|        148|       1.0|\n",
      "|SOYIYOG12A6D4F98CD|93b5fe4ed0c637099...|  3.0|      40953|        148|       4.0|\n",
      "|SOYIYOG12A6D4F98CD|67fd48ba403033681...|  5.0|      19667|        148|       2.0|\n",
      "|SOYIYOG12A6D4F98CD|fb81b0d99a247b7ce...|  4.0|      24217|        148|       3.0|\n",
      "+------------------+--------------------+-----+-----------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predicted plays\n",
    "predicted_plays.show(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had a RMSE on the test set of 7.5163240006236585\n"
     ]
    }
   ],
   "source": [
    "test_set = test_set.withColumn(\"Plays\", test_set[\"Plays\"].cast(DoubleType()))\n",
    "predict_df = my_model.transform(test_set)\n",
    "\n",
    "# Remove NaN values from prediction (due to SPARK-14489)\n",
    "Test_predictions = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "\n",
    "# Round floats to whole numbers\n",
    "Test_predictions = Test_predictions.withColumn(\"prediction\", F.abs(F.round(Test_predictions[\"prediction\"],0)))\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_df DataFrame\n",
    "Test_RMSE = reg_eval.evaluate(Test_predictions)\n",
    "print('The model had a RMSE on the test set of {0}'.format(Test_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|round(avg(Plays), 0)|\n",
      "+--------------------+\n",
      "|                 3.0|\n",
      "+--------------------+\n",
      "\n",
      "The average number of plays in the dataset is 3.0\n"
     ]
    }
   ],
   "source": [
    "# Comparing the Model\n",
    "avg_plays = train_set.groupBy().avg('Plays').select(F.round('avg(Plays)'))\n",
    "avg_plays.show(3)\n",
    "train_avg_plays = avg_plays.collect()[0][0]\n",
    "print('The average number of plays in the dataset is {0}'.format(train_avg_plays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the average set is 7.350144436048447\n"
     ]
    }
   ],
   "source": [
    "# Add a column with the average rating\n",
    "test_avg = test_set.withColumn('prediction', F.lit(train_avg_plays))\n",
    "\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the test_for_avg_df DataFrame\n",
    "test_avg_RMSE = reg_eval.evaluate(test_avg)\n",
    "print(\"The RMSE on the average set is {0}\".format(test_avg_RMSE))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## PREDICTION FOR AN USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs user has listened to:\n",
      "+--------------------+--------------------+\n",
      "|         artist_name|               title|\n",
      "+--------------------+--------------------+\n",
      "|       Justin Bieber|  Common Denominator|\n",
      "|Sean Kingston and...|        Eenie Meenie|\n",
      "|       Justin Bieber|              Bigger|\n",
      "|       Justin Bieber|        Runaway Love|\n",
      "|         John Legend|P.D.A. (We Just D...|\n",
      "|              Staind|Reply (Album Vers...|\n",
      "|         Los Pericos|            La Hiena|\n",
      "|      Colbie Caillat|              Bubbly|\n",
      "|         Lionel Rogg|Die Kunst der Fug...|\n",
      "|       Justin Bieber|            One Time|\n",
      "|       Justin Bieber| Stuck In The Moment|\n",
      "|       Dwight Yoakam|      You're The One|\n",
      "|           Morcheeba|             The Sea|\n",
      "|       Justin Bieber|             Love Me|\n",
      "|          Clara Hill|Clara meets Slope...|\n",
      "|       Justin Bieber|       Down To Earth|\n",
      "|      The Black Keys|All Hands Against...|\n",
      "|           Sam Cooke|    Ain't Misbehavin|\n",
      "|       Justin Bieber|             U Smile|\n",
      "|       Justin Bieber|       Favorite Girl|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Predicted Songs:\n",
      "+--------------------+--------------------+----------+\n",
      "|         artist_name|               title|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|           Sugarfree|               Sinta| 168.13539|\n",
      "|           PJ Harvey|         White Chalk| 148.91954|\n",
      "|Jadakiss / Lil Wayne|          Death Wish| 102.14449|\n",
      "|      Mulatu Astatke|I Faram Gami I Faram|  93.68719|\n",
      "|             Emarosa|The Past Should S...|  70.84239|\n",
      "|        Junior Kelly|     Jah Jah Live On| 63.076923|\n",
      "|                Pulp|         Born To Cry|  56.07692|\n",
      "|        Barren Cross|Imaginary Music (...|   54.8014|\n",
      "|        Niña Pastori|            Eres luz| 52.666233|\n",
      "| Theory Of A Deadman|Hello Lonely (Wal...|  52.00697|\n",
      "+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "UserID = 13\n",
    "songs_listened = plays_df_2.filter(plays_df_2.user_als_id == UserID) \\\n",
    "    .join(metadata_df, 'songId') \\\n",
    "    .select('song_als_id', 'artist_name', 'title') \\\n",
    " \\\n",
    "# Generating List of Listened Songs\n",
    "listened_songs_list = []\n",
    "for song in songs_listened.collect():\n",
    "    listened_songs_list.append(song['song_als_id'])\n",
    "\n",
    "print('Songs user has listened to:')\n",
    "songs_listened.select('artist_name', 'title').show()\n",
    "\n",
    "# generate dataframe of unlistened songs\n",
    "songs_unlistened = plays_df_2.filter( ~ plays_df_2['song_als_id'].isin(listened_songs_list)) \\\n",
    "    .select('song_als_id').withColumn('user_als_id', F.lit(UserID)).distinct()\n",
    "\n",
    "# feed unlistened songs into model\n",
    "predicted_listens = my_model.transform(songs_unlistened)\n",
    "\n",
    "# remove NaNs\n",
    "predicted_listens = predicted_listens.filter(predicted_listens['prediction'] != float('nan'))\n",
    "\n",
    "# print output\n",
    "print('Predicted Songs:')\n",
    "predicted_listens.join(plays_df_2, 'song_als_id') \\\n",
    "    .join(metadata_df, 'songId') \\\n",
    "    .select('artist_name', 'title', 'prediction') \\\n",
    "    .distinct() \\\n",
    "    .orderBy('prediction', ascending=False) \\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKING PREDICTIONS BASED ON  'SONGS LISTENED TO' AT LEAST TWICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enties with two or more plays: 1728069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[user_als_id: int, song_als_id: int, Plays: int]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plays_df_2more_plays = plays_df.join(user_als_id_LUT, 'userId') \\\n",
    "                                       .join(song_als_id_LUT, 'songId') \\\n",
    "                                       .filter(plays_df.Plays >= 2)\\\n",
    "                                       .distinct()\n",
    "\n",
    "total_entries_2more = plays_df_2more_plays.count()\n",
    "print('Total enties with two or more plays: {0}'.format(total_entries_2more))\n",
    "\n",
    "plays_df_2more_plays = plays_df_2more_plays.filter(plays_df_2more_plays.user_als_id < (unique_users)*0.8) \\\n",
    "                                                   .select('user_als_id', 'song_als_id', 'Plays')\n",
    "plays_df_2more_plays.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 828129, validation: 275653, test: 276379\n",
      "\n",
      "+-----------+-----------+-----+\n",
      "|user_als_id|song_als_id|Plays|\n",
      "+-----------+-----------+-----+\n",
      "|          6|          8|    2|\n",
      "|          7|         45|    3|\n",
      "|         12|        275|    5|\n",
      "+-----------+-----------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-----------+-----------+-----+\n",
      "|user_als_id|song_als_id|Plays|\n",
      "+-----------+-----------+-----+\n",
      "|        110|         11|  2.0|\n",
      "|        125|        273| 10.0|\n",
      "|        151|          8|  5.0|\n",
      "+-----------+-----------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-----------+-----------+-----+\n",
      "|user_als_id|song_als_id|Plays|\n",
      "+-----------+-----------+-----+\n",
      "|          6|         15|    3|\n",
      "|          7|         15|    6|\n",
      "|         12|        115|    2|\n",
      "+-----------+-----------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We'll hold out 60% for training, 20% of our data for validation, and leave 20% for testing\n",
    "seed = 1800083193\n",
    "(split_01, split_02, split_03) = plays_df_2more_plays.randomSplit([0.6, 0.2, 0.2], seed = seed)\n",
    "\n",
    "# Let's cache these datasets for performance\n",
    "trainset_2more = split_01.cache()\n",
    "validationset_2more = split_02.cache()\n",
    "testset_2more = split_03.cache()\n",
    "\n",
    "print('Training: {0}, validation: {1}, test: {2}\\n'.format(\n",
    "  trainset_2more.count(), validationset_2more.count(), testset_2more.count())\n",
    ")\n",
    "validationset_2more = validationset_2more.withColumn(\"Plays\", validationset_2more[\"Plays\"].cast(DoubleType()))\n",
    "test_2more = testset_2more.withColumn(\"Plays\", testset_2more[\"Plays\"].cast(DoubleType()))\n",
    "\n",
    "trainset_2more.show(3)\n",
    "validationset_2more.show(3)\n",
    "testset_2more.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALS_65afbd8a8382"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's initialize our ALS learner\n",
    "als_2more = ALS()\n",
    "\n",
    "# Now set the parameters for the method\n",
    "als_2more.setMaxIter(2)\\\n",
    "   .setSeed(seed)\\\n",
    "   .setItemCol(\"song_als_id\")\\\n",
    "   .setRatingCol(\"Plays\")\\\n",
    "   .setUserCol(\"user_als_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4, regularization parameter 0.1 the RMSE is 12.902847366010763\n",
      "For rank 8, regularization parameter 0.1 the RMSE is 12.418148607763834\n",
      "For rank 12, regularization parameter 0.1 the RMSE is 11.95593034209839\n",
      "For rank 16, regularization parameter 0.1 the RMSE is 11.231182460051976\n",
      "For rank 4, regularization parameter 0.15 the RMSE is 11.811508335215171\n",
      "For rank 8, regularization parameter 0.15 the RMSE is 11.22740415240161\n",
      "For rank 12, regularization parameter 0.15 the RMSE is 10.731303477347986\n",
      "For rank 16, regularization parameter 0.15 the RMSE is 10.363964007086643\n",
      "For rank 4, regularization parameter 0.2 the RMSE is 11.176796354061143\n",
      "For rank 8, regularization parameter 0.2 the RMSE is 10.599910145664028\n",
      "For rank 12, regularization parameter 0.2 the RMSE is 10.157671030809718\n",
      "For rank 16, regularization parameter 0.2 the RMSE is 9.913135472681212\n",
      "For rank 4, regularization parameter 0.25 the RMSE is 10.766626184988802\n",
      "For rank 8, regularization parameter 0.25 the RMSE is 10.215313197060043\n",
      "For rank 12, regularization parameter 0.25 the RMSE is 9.866637977600906\n",
      "For rank 16, regularization parameter 0.25 the RMSE is 9.684414232445043\n",
      "The best model was trained with regularization parameter 0.25\n",
      "The best model was trained with rank 16\n"
     ]
    }
   ],
   "source": [
    "# Now let's compute an evaluation metric for our test dataset\n",
    "# We Create an RMSE evaluator using the label and predicted columns\n",
    "reg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"Plays\", metricName=\"rmse\")\n",
    "\n",
    "tolerance = 0.03\n",
    "ranks = [4, 8, 12, 16]\n",
    "regParams = [0.1, 0.15, 0.2, 0.25]\n",
    "errors = [[0]*len(ranks)]*len(regParams)\n",
    "models = [[0]*len(ranks)]*len(regParams)\n",
    "err = 0\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "i = 0\n",
    "for regParam in regParams:\n",
    "  j = 0\n",
    "  for rank in ranks:\n",
    "    # Set the rank here:\n",
    "    als_2more.setParams(rank = rank, regParam = regParam)\n",
    "    # Create the model with these parameters.\n",
    "    model = als_2more.fit(trainset_2more)\n",
    "    # Run the model to create a prediction. Predict against the validation_df.\n",
    "    predict_df = model.transform(validationset_2more)\n",
    "\n",
    "    # Remove NaN values from prediction (due to SPARK-14489)\n",
    "    predicted_plays_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "    predicted_plays_df = predicted_plays_df.withColumn(\"prediction\", F.abs(F.round(predicted_plays_df[\"prediction\"],0)))\n",
    "    # Run the previously created RMSE evaluator, reg_eval, on the predicted_ratings_df DataFrame\n",
    "    error = reg_eval.evaluate(predicted_plays_df)\n",
    "    errors[i][j] = error\n",
    "    models[i][j] = model\n",
    "    print ('For rank %s, regularization parameter %s the RMSE is %s' % (rank, regParam, error))\n",
    "    if error < min_error:\n",
    "      min_error = error\n",
    "      best_params = [i,j]\n",
    "    j += 1\n",
    "  i += 1\n",
    "\n",
    "als_2more.setRegParam(regParams[best_params[0]])\n",
    "als_2more.setRank(ranks[best_params[1]])\n",
    "print ('The best model was trained with regularization parameter %s' % regParams[best_params[0]])\n",
    "print ('The best model was trained with rank %s' % ranks[best_params[1]])\n",
    "my_model_2more = models[best_params[0]][best_params[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the Model on the Test_2more Dataset\n",
    "predict_2more = my_model_2more.transform(test_2more)\n",
    "\n",
    "# Remove NaN values from prediction \n",
    "predicted_test_2more = predict_2more.filter(predict_2more.prediction != float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had a RMSE on the test set of 9.66994003417862\n"
     ]
    }
   ],
   "source": [
    "# Round floats to whole numbers\n",
    "predicted_test_2more = predicted_test_2more.withColumn(\"prediction\", F.abs(F.round(predicted_test_2more[\"prediction\"],0)))\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_df DataFrame\n",
    "test2more_RMSE = reg_eval.evaluate(predicted_test_2more)\n",
    "\n",
    "print('The model had a RMSE on the test set of {0}'.format(test2more_RMSE))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Comparing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|round(avg(Plays), 0)|\n",
      "+--------------------+\n",
      "|                 6.0|\n",
      "+--------------------+\n",
      "\n",
      "The average number of plays in the dataset is 6.0\n",
      "The RMSE on the average set is 8.643135682564385\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##We again compare to selecting the average number of plays from the training dataset\n",
    "avg_plays_2more = trainset_2more.groupBy().avg('Plays').select(F.round('avg(Plays)'))\n",
    "\n",
    "avg_plays_2more.show(3)\n",
    "# Extract the average rating value. (This is row 0, column 0.)\n",
    "train_avg_plays2more = avg_plays_2more.collect()[0][0]\n",
    "\n",
    "print('The average number of plays in the dataset is {0}'.format(train_avg_plays2more))\n",
    "\n",
    "# Add a column with the average rating\n",
    "test_for_avg_2more = test_2more.withColumn('prediction', F.lit(train_avg_plays2more))\n",
    "\n",
    "# Run the previously created RMSE evaluator, reg_eval, on the test_for_avg_df DataFrame\n",
    "test_avg_RMSE_2more = reg_eval.evaluate(test_for_avg_2more)\n",
    "\n",
    "print(\"The RMSE on the average set is {0}\".format(test_avg_RMSE_2more))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs user has listened to:\n",
      "+--------------------+--------------------+\n",
      "|         artist_name|               title|\n",
      "+--------------------+--------------------+\n",
      "|       Justin Bieber|  Common Denominator|\n",
      "|Sean Kingston and...|        Eenie Meenie|\n",
      "|       Justin Bieber|              Bigger|\n",
      "|       Justin Bieber|        Runaway Love|\n",
      "|         John Legend|P.D.A. (We Just D...|\n",
      "|              Staind|Reply (Album Vers...|\n",
      "|         Los Pericos|            La Hiena|\n",
      "|      Colbie Caillat|              Bubbly|\n",
      "|         Lionel Rogg|Die Kunst der Fug...|\n",
      "|       Justin Bieber|            One Time|\n",
      "|       Justin Bieber| Stuck In The Moment|\n",
      "|       Dwight Yoakam|      You're The One|\n",
      "|           Morcheeba|             The Sea|\n",
      "|       Justin Bieber|             Love Me|\n",
      "|          Clara Hill|Clara meets Slope...|\n",
      "|       Justin Bieber|       Down To Earth|\n",
      "|      The Black Keys|All Hands Against...|\n",
      "|           Sam Cooke|    Ain't Misbehavin|\n",
      "|       Justin Bieber|             U Smile|\n",
      "|       Justin Bieber|       Favorite Girl|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Predicted Songs:\n",
      "+--------------------+--------------------+----------+\n",
      "|         artist_name|               title|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|                Omen|         Death Rider|  959.0753|\n",
      "|              Mogwai|Take Me Somewhere...| 184.33499|\n",
      "|          Grinderman|Get It On (Explicit)|  144.9884|\n",
      "|           Goatwhore|   Apocalyptic Havoc|121.417145|\n",
      "|            Keb' Mo'|            Angelina| 112.28636|\n",
      "|            Republic|    Túl sok a király| 104.64465|\n",
      "|        Niña Pastori|            Eres luz| 91.972946|\n",
      "|Jadakiss / Lil Wayne|          Death Wish|  87.98976|\n",
      "|      Patrick Jumpen|             Holiday|  86.36835|\n",
      "|               Halou|          Separation| 85.798096|\n",
      "+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PREDICTION FOR THE USER - 02\n",
    "UserID = 13\n",
    "songs_listened = plays_df_2.filter(plays_df_2.user_als_id == UserID) \\\n",
    "    .join(metadata_df, 'songId') \\\n",
    "    .select('song_als_id', 'artist_name', 'title') \\\n",
    " \\\n",
    "# Generating List of Listened Songs\n",
    "listened_songs_list = []\n",
    "for song in songs_listened.collect():\n",
    "    listened_songs_list.append(song['song_als_id'])\n",
    "\n",
    "print('Songs user has listened to:')\n",
    "songs_listened.select('artist_name', 'title').show()\n",
    "\n",
    "# generate dataframe of unlistened songs\n",
    "songs_unlistened = plays_df_2.filter( ~ plays_df_2['song_als_id'].isin(listened_songs_list)) \\\n",
    "    .select('song_als_id').withColumn('user_als_id', F.lit(UserID)).distinct()\n",
    "\n",
    "# feed unlistened songs into model\n",
    "predicted_listens = my_model_2more.transform(songs_unlistened)\n",
    "\n",
    "# remove NaNs\n",
    "predicted_listens = predicted_listens.filter(predicted_listens['prediction'] != float('nan'))\n",
    "\n",
    "# print output\n",
    "print('Predicted Songs:')\n",
    "predicted_listens.join(plays_df_2, 'song_als_id') \\\n",
    "    .join(metadata_df, 'songId') \\\n",
    "    .select('artist_name', 'title', 'prediction') \\\n",
    "    .distinct() \\\n",
    "    .orderBy('prediction', ascending=False) \\\n",
    "    .show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
